import json
import vk_api
import os
from pathlib import Path
import time
import datetime
from urllib.parse import urlparse
from vk_api.vk_api import VkApiMethod
from typing import TextIO, Optional
from tqdm import tqdm
from dotenv import load_dotenv

from utils.logger import get_logger

logger = get_logger(__name__)


def _get_group_domain(url):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç domain –≥—Ä—É–ø–ø—ã –∏–∑ —Å—Å—ã–ª–∫–∏"""
    return urlparse(url).path.strip("/")


def _get_posts(vk: VkApiMethod, domain: str, count: int, offset: int):
    # –î–æ–±–∞–≤–ª—è–µ–º filter='owner' —á—Ç–æ–±—ã –ø–æ–ª—É—á–∞—Ç—å –ø–æ—Å—Ç—ã –∏–º–µ–Ω–Ω–æ –æ—Ç –∏–º–µ–Ω–∏ –≥—Ä—É–ø–ø—ã,
    # –∞ –Ω–µ –≤—Å–µ –ø–æ–¥—Ä—è–¥ (—Ö–æ—Ç—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é usually 'all').
    response = vk.wall.get(domain=domain, count=count, offset=offset, filter="owner")
    posts = response.get("items", [])
    return posts


def _to_output_dict(post: dict, name: str) -> dict:
    result = dict()
    result["url"] = f"https://vk.com/wall{post['owner_id']}_{post['id']}"
    result["name"] = name
    result["content"] = post.get("text", " ")

    result["date"] = post.get("date")
    result["collection_date"] = int(time.time())

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if "is_pinned" in post:
        result["is_pinned"] = post["is_pinned"]

    return result


def _collect_data(
    vk: VkApiMethod,
    domain: str,
    title: str,
    out: TextIO,
    batch_size: int = 100,
    cutoff_date: Optional[int] = None,
) -> tuple[Optional[int], Optional[int]]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (min_date, max_date) –¥–ª—è —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
    """
    offset = 0
    saved_count = 0
    should_stop = False
    min_date = None
    max_date = None

    # –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ —Å–∫–∞—á–∏–≤–∞–µ–º –ø–æ—Å—Ç—ã, –ø–æ–∫–∞ –æ–Ω–∏ –µ—Å—Ç—å –∏ –Ω–µ –¥–æ—Å—Ç–∏–≥–ª–∏ cutoff_date
    with tqdm(desc=f'–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≥—Ä—É–ø–ø—ã "{title}"') as pbar:
        while True:
            if should_stop:
                break

            posts = _get_posts(vk, domain, count=batch_size, offset=offset)

            # –ï—Å–ª–∏ –ø–æ—Å—Ç–æ–≤ –Ω–µ—Ç, –∑–Ω–∞—á–∏—Ç –¥–æ—à–ª–∏ –¥–æ –∫–æ–Ω—Ü–∞
            if not posts:
                break

            for post in posts:
                post_date = post.get("date")
                is_pinned = post.get("is_pinned", 0) == 1

                # –í–∞–∂–Ω–æ: –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–π –ø–æ—Å—Ç (pinned) –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç–∞—Ä—ã–º.
                # –ú—ã –µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º, –Ω–æ –ù–ï –ø—Ä–µ—Ä—ã–≤–∞–µ–º —Å–±–æ—Ä, –µ—Å–ª–∏ –æ–Ω —Å—Ç–∞—Ä—à–µ cutoff_date.
                # –ü—Ä–µ—Ä—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞ –û–ë–´–ß–ù–´–• –ø–æ—Å—Ç–∞—Ö (—Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö).
                if not is_pinned:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—Ç–∞—Ä—à–µ –ª–∏ –ø–æ—Å—Ç, —á–µ–º cutoff_date
                    if cutoff_date is not None and post_date < cutoff_date:
                        should_stop = True
                        break  # Break inner loop

                # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞—Ç—ã (–≤–∫–ª—é—á–∞—è pinned –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ)
                if min_date is None or post_date < min_date:
                    min_date = post_date
                if max_date is None or post_date > max_date:
                    max_date = post_date

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º
                out_post = _to_output_dict(post, title)
                json_line = json.dumps(out_post, ensure_ascii=False)

                out.write(json_line + "\n")
                saved_count += 1

            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –±—É—Ñ–µ—Ä –Ω–∞ –¥–∏—Å–∫
            out.flush()

            offset += len(posts)
            pbar.update(len(posts))

            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞
            time.sleep(0.3)

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞ –≤ –ª–æ–≥
    min_str = (
        datetime.datetime.fromtimestamp(min_date).strftime("%Y-%m-%d %H:%M:%S")
        if min_date is not None
        else "N/A"
    )
    max_str = (
        datetime.datetime.fromtimestamp(max_date).strftime("%Y-%m-%d %H:%M:%S")
        if max_date is not None
        else "N/A"
    )

    logger.info(
        f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –ø–æ—Å—Ç–æ–≤. –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç: {min_str} - {max_str}"
    )

    return min_date, max_date


def _autorize(token: str | None) -> VkApiMethod:
    vk_session = vk_api.VkApi(token=token)
    vk: VkApiMethod = vk_session.get_api()
    return vk


def _get_groups(filepath: Path) -> dict:
    with open(filepath, "r", encoding="utf-8") as f:
        groups_dict = json.load(f)
    return groups_dict


def _save_posts(
    vk: VkApiMethod,
    groups_dict: dict,
    output_filepath: Path,
    cutoff_unix_date: int | None = None,
    posts_per_prequest: int = 100,
):
    cutoff_info = ""
    if cutoff_unix_date is not None:
        cutoff_info = f" (—Å {datetime.datetime.fromtimestamp(cutoff_unix_date)})"

    logger.info(f"–ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø: {len(groups_dict)}")
    logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä –≤ {output_filepath}{cutoff_info}...")

    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –æ–±—â–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É
    global_min_date = None
    global_max_date = None

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º 'w' –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞ –ø—Ä–∏ –Ω–æ–≤–æ–º –∑–∞–ø—É—Å–∫–µ.
    # –§–∞–π–ª vk_scrapped.jsonl –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–æ–Ω–∞.
    with open(output_filepath, "w", encoding="utf-8") as f_out:
        for title, link in groups_dict.items():
            domain = _get_group_domain(link)
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≥—Ä—É–ø–ø—ã {title}...")

            try:
                min_date, max_date = _collect_data(
                    vk,
                    domain,
                    title,
                    f_out,
                    posts_per_prequest,
                    cutoff_unix_date,
                )

                # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –¥–∞—Ç—ã
                if min_date is not None:
                    if global_min_date is None or min_date < global_min_date:
                        global_min_date = min_date

                if max_date is not None:
                    if global_max_date is None or max_date > global_max_date:
                        global_max_date = max_date

            except vk_api.exceptions.ApiError as e:
                logger.info(f"\n‚ö†Ô∏è –û—à–∏–±–∫–∞ API ({title}): {e}")
            except Exception as e:
                logger.info(f"\n‚ö†Ô∏è –û—à–∏–±–∫–∞ ({title}): {e}")

    min_date_str = "nan"
    if global_min_date is not None:
        min_date_str = datetime.datetime.fromtimestamp(global_min_date).strftime(
            "%Y-%m-%d"
        )

    max_date_str = "nan"
    if global_max_date is not None:
        max_date_str = datetime.datetime.fromtimestamp(global_max_date).strftime(
            "%Y-%m-%d"
        )

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Å –¥–∞—Ç–∞–º–∏
    new_name = (
        output_filepath.stem
        + f"_{min_date_str}_to_{max_date_str}"
        + output_filepath.suffix
    )
    new_path = output_filepath.parent / new_name

    output_filepath.rename(new_path)
    logger.info(f"üéâ –ì–æ—Ç–æ–≤–æ! –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_filepath}")
    logger.info(f"   –î–∏–∞–ø–∞–∑–æ–Ω: —Å {min_date_str} –ø–æ {max_date_str}")


def crawl_vk_knowledge(
    vk_token: str,
    urls_filepath: Path,
    output_filepath: Path,
    cutoff_unix_date: int | None,
    posts_per_prequest: int = 100,
):
    # 1. –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
    try:
        vk = _autorize(vk_token)
    except Exception as e:
        logger.info(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
        return

    # 2. –ß—Ç–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≥—Ä—É–ø–ø
    try:
        groups_dict = _get_groups(urls_filepath)
    except FileNotFoundError:
        logger.info(f"‚ùå –§–∞–π–ª {urls_filepath} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    _save_posts(vk, groups_dict, output_filepath, cutoff_unix_date, posts_per_prequest)


def main():
    BASE = Path(__file__).resolve().parent.parent
    RESOURCES_DIR = BASE.joinpath("urls")
    SCRAPPED_DATA_DIR = BASE.joinpath("scrapped_data")

    # –ó–∞–¥–∞—ë–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    load_dotenv()

    # –°–µ—Ä–≤–∏—Å–Ω—ã–π –∫–ª—é—á –¥–æ—Å—Ç—É–ø–∞
    VK_SERVICE_TOKEN = os.getenv("VK_SERVICE_TOKEN")
    if VK_SERVICE_TOKEN is None:
        raise ValueError("‚ùå –í .env —Ñ–∞–π–ª–µ –Ω–µ –∑–∞–¥–∞–Ω VK_SERVICE_TOKEN")

    # –ò–º—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    INPUT_FILE = RESOURCES_DIR.joinpath("vk_urls.json")

    # –§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–í crawl_vk_knowledge –∫ –Ω–∞–∑–≤–∞–Ω–∏—é —Ñ–∞–π–ª–∞ –¥–æ–±–∞–≤—è—Ç—Å—è –¥–∞—Ç—ã)
    OUTPUT = SCRAPPED_DATA_DIR.joinpath("vk_scrapped.jsonl")

    # –î–∞—Ç–∞, –ù–ê–ß–ò–ù–ê–Ø –° –ö–û–¢–û–†–û–ô —Å–∫—Ä–∞–ø–ø–∏—Ç—å –ø–æ—Å—Ç—ã (Unix timestamp)
    #
    # –°–∫—Ä–∏–ø—Ç —Å–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –ø–æ—Å—Ç—ã –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ –º–æ–º–µ–Ω—Ç–∞ –Ω–∞–∑–∞–¥ –¥–æ —ç—Ç–æ–π –¥–∞—Ç—ã.
    # None = —Å–∫—Ä–∞–ø–ø–∏—Ç—å –≤—Å–µ –ø–æ—Å—Ç—ã –∑–∞ –≤—Å—ë –≤—Ä–µ–º—è
    # –ü—Ä–∏–º–µ—Ä: 1609459200 –¥–ª—è 2021-01-01
    # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: int(datetime.datetime(2020, 1, 1).timestamp())
    CUTOFF_DATE = None  # int(datetime.datetime(2026, 1, 1).timestamp())

    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å—Ç–æ–≤ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–º–∞–∫—Å–∏–º—É–º 100 –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å)
    POSTS_PER_REQUEST = 100

    crawl_vk_knowledge(
        VK_SERVICE_TOKEN, INPUT_FILE, OUTPUT, CUTOFF_DATE, POSTS_PER_REQUEST
    )


if __name__ == "__main__":
    main()
