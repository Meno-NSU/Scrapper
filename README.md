# NSU Scrapper

Многоисточниковый скраппер для сбора информационного контента Новосибирского государственного университета (НГУ) из разных источников.

Проект собирает образовательный контент НГУ из **двух источников**:

1. **ВКонтакте** - посты из официальной группы университета
2. **Веб-сайт НГУ** - образовательные страницы, программы, информацию о факультетах

Собранные данные сохраняются в соответствующих файлах в формате `JSONL` для последующей обработки и анализа.

После сбора данных происходит объединение двух jsonl файлов в единный jsonl
---

## Структура проекта

```
Scrapper/
├── crawl_nsu_vk_knowledge.py                   # Скраппер группы ВКонтакте (берет ссылки из vk_urls.json, генерирует vk_scrapped_<date_1>_to_<date_2>.jsonl)
├── crawl_nsu_web_knowledge.py                  # Скраппер веб-сайта (берет ссылки из web_urls.json, генерирует web_scrapped_<date>.jsonl)
├── merge_knowledge.py                          # Скрипт для объединения последних собранных данных с разных источников (если сохранено несколько файлов vk_scrapped/web_scrapped, то берём те, у которых date_2/date новее)
├── nsu_urls_spider.py                          # Паук для поиска URLs на сайте НГУ (использовался для получения части ссылок из web_urls.json)
├── resources/
│   ├── vk_urls.json                            # Список ВК групп для сбора информации
│   └── web_urls.json                           # Список веб-страниц НГУ для сбора информации
└── scrapped_data/
    ├── vk_scrapped_<date_1>_to_<date_2>.jsonl  # Собранные посты из ВК в период с <date_1> по <date_2>
    ├── web_scrapped_<date>.jsonl               # Собранный контент с веб-сайта c датой сбора <date>
    └── merged_latest_knowledge.jsonl           # Объединение vk_scrpped и web_scrapped (Если есть несколько vk_scrapped/web_scrapped, то берём те, у которых date_2/date новее)
```

## Установка

### Требования

- Python 3.13+
- [uv](https://docs.astral.sh/uv/) - пакетный менеджер и координатор рабочего окружения

### Шаги установки

1. **Установите зависимости**
   ```bash
   uv sync
   ```

   Для установки зависимостей разработки (включая Jupyter):
   ```bash
   uv sync --all-extras
   ```

2. **Активируйте виртуальное окружение**
   ```bash
   source .venv/bin/activate
   ```

4. **Создайте `.env` файл из шаблона**
   ```bash
   cp .env.sample .env
   ```

   Отредактируйте `.env` и добавьте необходимые переменные:
   - `VK_SERVICE_TOKEN` - сервисный токен VK API (получите на https://vk.com/dev)
